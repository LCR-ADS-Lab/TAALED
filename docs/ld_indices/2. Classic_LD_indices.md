
# Calculate Classic (but Flawed) LD Indices
ðŸ’¡ For more information about the lexical diversity indices calculated by taaled, read **â–¶ï¸ŽLEARN MORE**.

## Type-token ratio (TTR)<sup>â˜…â˜†â˜†</sup>

<img src="https://latex.codecogs.com/svg.latex?\fn_cm&space;TTR&space;=&space;\frac{nTypes}{nTokens}" title="TTR = \frac{nTypes}{nTokens}" />

TTR is calculated as the number of unique words in a text (types) divided by the number of running words (tokens)(Johnson, 1944<sup>[8](https://lcr-ads-lab.github.io/TAALED/references/1.%20Studies.html#johnson-w-1944)</sup>).

```python
print(ldvals.ttr)
```
```result
0.5507246376811594
```

## Root TTR<sup>â˜…â˜†â˜†</sup>

<img src="https://latex.codecogs.com/svg.latex?\fn_cm&space;Root&space;TTR&space;=&space;\frac{nTypes}{\sqrt{nTokens}}" title="Root TTR = \frac{nTypes}{\sqrt{nTokens}}" />

Root TTR is calculated as the number of types divided by the square root of the number of tokens (Guiraud, 1960<sup>[4](https://lcr-ads-lab.github.io/TAALED/references/1.%20Studies.html#guiraud-p-1960)</sup>, also called *Guirad's index*).

```python
print(ldvals.rttr)
```
```result
9.14932483451846
```
## Log TTR<sup>â˜…â˜†â˜†</sup>

<img src="https://latex.codecogs.com/svg.latex?\fn_cm&space;Log&space;TTR&space;=&space;\frac{log(nTypes)}{log(nTokens)}" title="Log TTR = \frac{log(nTypes)}{log(nTokens)}" />

Log TTR is calculated by dividing the logarithm of the number of word types by the logarithm of the number of word tokens (Chotlos, 1944<sup>[2](https://lcr-ads-lab.github.io/TAALED/references/1.%20Studies.html#chotlos-j-w-1944)</sup>; Herdan, 1960<sup>[5](https://lcr-ads-lab.github.io/TAALED/references/1.%20Studies.html#herdan-g-1960)</sup>, also known as *Herdan's C*).
```python
print(ldvals.lttr)
```
```result
0.8938651603109881
```

## MSTTR<sup>â˜…â˜†â˜†</sup>
The Mean-Segmental Type-Token Ratio (MSTTR) is the average TTR for successive segments of text containing a standard number of word tokens (Johnson, 1944<sup>[8](https://lcr-ads-lab.github.io/TAALED/references/1.%20Studies.html#johnson-w-1944)</sup>).
```python
print(ldvals.msttr)
```
```result
0.796
```

----------------------------------
â–¶ï¸Ž**LEARN MORE**

* TTR is perhaps the most well known LD index. Johnson (1939, 1944<sup>[8](https://lcr-ads-lab.github.io/TAALED/references/1.%20Studies.html#johnson-w-1944)</sup>), in the field of psychology, discussed the type-token ratio (TTR) applying the terms type and token coined by Peirce (1906, pp. 505-506) in order to come up with reliable measures of language behavior (p. 1). Johnson (1944)<sup>[8](https://lcr-ads-lab.github.io/TAALED/references/1.%20Studies.html#johnson-w-1944)</sup>, listed varying statistical or mathematical procedures of TTRs, which include _the ove-all TTR_, the _mean segmental TTR_, and _the cumulative TTR curve_, _the decremental TTR curve_, and _type frequencies_, and etc.

* MSTTR originally referts to _the mean segmental TTR_ introduced by Johnson (1944)<sup>[8](https://lcr-ads-lab.github.io/TAALED/references/1.%20Studies.html#johnson-w-1944)</sup>. He thought that *the mean segmental TTR* makes the samples of different magnitudes can be compared by dividing each sample into like-sized segments (e.g., 100 words each), computing the TTR for each segment and then averaging the segmental TTR's for each example. As long as the samples represent the segments of equal size, they are comparable.

* Root TTR and Log TTR were two early attempts to correct for TTR's sensitivity to text length using simple mathematical transformations.

* TTR values are intrinsically skewed by the length of a text, wherein longer texts tend to have lower TTR scores because the proportion of repeated words increases as the text grows longer (e.g., Koizumi & In'nami, 2012<sup>[10](https://lcr-ads-lab.github.io/TAALED/references/1.%20Studies.html#koizumi-r--innami-y-2012)</sup>; Tweedie & Baayen, 1998<sup>[18](https://lcr-ads-lab.github.io/TAALED/references/1.%20Studies.html#tweedie-f-j--baayen-r-h-1998)</sup>).

* Hess, Sefton, and Jandry (1986)<sup>[7](https://lcr-ads-lab.github.io/TAALED/references/1.%20Studies.html#hess-c-w-sefton-k-m--landry-r-g-1986)</sup> analyzed oral language samples from 83 preschool children using five LD measures that were popular at the time: simple TTR, corrected TTR (Carroll, 1964<sup>[1](https://lcr-ads-lab.github.io/TAALED/references/1.%20Studies.html#carroll-j-b-1964)</sup>), Root TTR, Log TTR, and Characteristic K (Yule, 1944<sup>[19](https://lcr-ads-lab.github.io/TAALED/references/1.%20Studies.html#yule-g-u-1944)</sup>). They concluded that all these LD measures were unsuitable for comparing texts of different lengths.

* Hess, Haug, and Landry (1989)<sup>[6](https://lcr-ads-lab.github.io/TAALED/references/1.%20Studies.html#hess-c-w-haug-h--landry-r-g-1989)</sup> used oral language samples from 52 elementary school children to analyze four versions of TTR: simple TTR, corrected TTR, Root TTR, and Log TTR. As was the case in the earlier study by Hess et al. (1986)<sup>[7](https://lcr-ads-lab.github.io/TAALED/references/1.%20Studies.html#hess-c-w-sefton-k-m--landry-r-g-1986)</sup>, results suggested that none of the TTR measures were stable across texts of different lengths.

* Baayen & Tweedy (1998)<sup>[18](https://lcr-ads-lab.github.io/TAALED/references/1.%20Studies.html#tweedie-f-j--baayen-r-h-1998)</sup> ... This needs to be added!

* McCarthy and Jarvis (2007)<sup>[16](https://lcr-ads-lab.github.io/TAALED/references/1.%20Studies.html#mccarthy-p-m--jarvis-s-2007)</sup> used a parallel sampling technique to investigate the relationship between text length and LD indices in an L1 corpus of speaking and writing. They found that most indices (including TTR and root TTR) were strongly correlated with the text length.

* In Malvern & Richards (2002)<sup>[12](https://lcr-ads-lab.github.io/TAALED/references/1.%20Studies.html#malvern-d--richards-b-2002)</sup>, MSTTR computes TTR values for equal-sized segments (sometimes 30 words, but more typically 100 words) out of the original text and averages the values for each non-overlapping segments. The remaining words are discarded. However, a number of weaknesses have been identified in this approach.

* Zenker & Kyle (2021)<sup>[20](https://lcr-ads-lab.github.io/TAALED/references/1.%20Studies.html#zenker-f--kyle-k-2021)</sup> ... This needs to be added!
