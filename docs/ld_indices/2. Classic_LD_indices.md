
# Calculate Classic (but Flawed) LD Indices
A number of lexical diversity indices have been proposed and used in fields such as educational psychology, applied linguistics, and other fields that include text analytics. An important issue with the use of lexical diversity indices (particularly when they are used to index an aspect of writing/speaking proficiency) is that many of these indices are intrinsically related to text length. Text length is a reasonable (if imperfect) **general** index of writing/speaking proficiency. It is, however, rather imprecise as a number of factors can be related to text length (fluency, development of ideas, etc.). **If we want to measure the construct of lexical diversity itself, we need to use indices that are independent of text length.**

Indices such as TTR are **_negatively_** correlated with text length. This is problematic because we would expect more proficient writers/speakers to both write longer texts (higher fluency, ability to create more elaborated texts, etc.), but we would also expect more proficient writers/speakers to write more diverse texts. 

Indices such as Root TTR (also referred to as Guiraud's Index) are **_positively_** correlated with text length. This is problematic because it overestimates diversity of lexical items in a text (and conflates lexical diversity with other constructs such as fluency and development).

üí° For more information about the lexical diversity indices calculated by taaled, see the **LEARN MORE** section at the bottom of this page.

**[Review] Create a *ldvals object***

All the commands on this page assume that you have created a `ldvals` object. The following is the recap on how to creat it using the sample text provided in the package.
```python
from taaled import ld #import a package
from pylats import lats #used for preprocessing in this example, but optional in your analysis
clnsmpl = lats.Normalize(ld.txtsmpl, ld.params) #preprocessing

ldvals = ld.lexdiv(clnsmpl.toks) #calculate LD indices
```

## Type-token ratio (TTR)<sup>‚òÖ‚òÜ‚òÜ</sup>

<img src="https://latex.codecogs.com/svg.latex?\fn_cm&space;TTR&space;=&space;\frac{nTypes}{nTokens}" title="TTR = \frac{nTypes}{nTokens}" />

TTR is calculated as the number of unique words in a text (types) divided by the number of running words (tokens) (Johnson, 1944<sup>[9](https://lcr-ads-lab.github.io/TAALED/references/1.%20Related%20Studies.html#johnson-w-1944)</sup>).
To get the TTR value, use `.ttr` method.
```python
print(ldvals.ttr)
```
```result
0.5507246376811594
```

## Root TTR<sup>‚òÖ‚òÜ‚òÜ</sup>

<img src="https://latex.codecogs.com/svg.latex?\fn_cm&space;Root&space;TTR&space;=&space;\frac{nTypes}{\sqrt{nTokens}}" title="Root TTR = \frac{nTypes}{\sqrt{nTokens}}" />

Root TTR is calculated as the number of types divided by the square root of the number of tokens (Guiraud, 1960<sup>[4](https://lcr-ads-lab.github.io/TAALED/references/1.%20Related%20Studies.html#guiraud-p-1960)</sup>, also called *Guiraud's index*).
To get the RTTR value, use `.rttr` method.

```python
print(ldvals.rttr)
```
```result
9.14932483451846
```
## Log TTR<sup>‚òÖ‚òÜ‚òÜ</sup>

<img src="https://latex.codecogs.com/svg.latex?\fn_cm&space;Log&space;TTR&space;=&space;\frac{log(nTypes)}{log(nTokens)}" title="Log TTR = \frac{log(nTypes)}{log(nTokens)}" />

Log TTR is calculated by dividing the logarithm of the number of word types by the logarithm of the number of word tokens (Chotlos, 1944<sup>[2](https://lcr-ads-lab.github.io/TAALED/references/1.%20Related%20Studies.html#chotlos-j-w-1944)</sup>; Herdan, 1960<sup>[5](https://lcr-ads-lab.github.io/TAALED/references/1.%20Related%20Studies.html#herdan-g-1960)</sup>, also known as *Herdan's C*).
To get the Log TTR value, use `.lttr` method.

```python
print(ldvals.lttr)
```
```result
0.8938651603109881
```

## MSTTR<sup>‚òÖ‚òÜ‚òÜ</sup>
The Mean-Segmental Type-Token Ratio (MSTTR) is the average TTR for successive segments of text containing a standard number of word tokens (Johnson, 1939, 1944<sup>[9](https://lcr-ads-lab.github.io/TAALED/references/1.%20Related%20Studies.html#johnson-w-1944)</sup>). According to Jarvis & Hashimoto (2021)<sup>[8](https://lcr-ads-lab.github.io/TAALED/references/1.%20Related%20Studies.html#jarvis-s--hashimoto-b-j-2021)</sup>, it was the only LD measure that had compelling evidence of overcoming the text-length sensitivity problem in the early 2000s.

After Johnson recognized the text-length problem of TTR, he suggested a solution to break the text into a number of evenly-sized segments, calculating the TTR of each segment, and measuring the mean TTR across all segments. Even though this index appears to be independent of the text length, many researchers (e.g., Covington & McFall, 2010<sup>[3](https://lcr-ads-lab.github.io/TAALED/references/1.%20Related%20Studies.html#covington-m-a--mcfall-j-d-2010)</sup>; Malvern et al., 2004<sup>[16]()</sup> ; McCarthy & Jarvis, 2010<sup>[19](https://lcr-ads-lab.github.io/TAALED/references/1.%20Related%20Studies.html#mccarthy-p-m--jarvis-s-2010)</sup>) have addressed that MSTTR is flawed in that it drops the remaining (and potentially valuable) data (see Jarvis & Hashimoto, 2021<sup>[8](https://lcr-ads-lab.github.io/TAALED/references/1.%20Related%20Studies.html#jarvis-s--hashimoto-b-j-2021)</sup>, p.165).

To get the MSTTR value, use `.msttr` method.

```python
print(ldvals.msttr)
```
```result
0.796
```

## LEARN MORE

* TTR is perhaps the most well known LD index. Johnson (1939, 1944<sup>[9](https://lcr-ads-lab.github.io/TAALED/references/1.%20Related%20Studies.html#johnson-w-1944)</sup>), in the field of psychology, discussed the type-token ratio (TTR) to come up with reliable measures of language behavior. He also listed varying statistical or mathematical procedures of TTRs, which include _the over-all TTR_, the _mean segmental TTR_, and _the cumulative TTR curve_, _the decremental TTR curve_, and _type frequencies_, and etc. Here, the mean segmental TTR refers to MSTTR. He thought that the MSTTR makes the samples of different magnitudes can be compared by dividing each sample into like-sized segments (e.g., 100 words each), computing the TTR for each segment and then averaging the segmental TTR's for each example. As long as the samples represent the segments of equal size, they are comparable. However, according to Hess, Sefton, and Jandry (1986)<sup>[7](https://lcr-ads-lab.github.io/TAALED/references/1.%20Related%20Studies.html#hess-c-w-sefton-k-m--landry-r-g-1986)</sup>, all the four measures have been criticized due to its sensitivity to the text length.

* Root TTR and Log TTR were two early attempts to correct for TTR's sensitivity to text length using simple mathematical transformations. Chotlos (1944)<sup>[2](https://lcr-ads-lab.github.io/TAALED/references/1.%20Related%20Studies.html#chotlos-j-w-1944)</sup> presented a log TTR graph (i.e., the relationship of the log number of tokens and the log number of types) of the L1 children‚Äôs writing samples. Herdan (1960)<sup>[5](https://lcr-ads-lab.github.io/TAALED/references/1.%20Related%20Studies.html#herdan-g-1960)</sup> also explored the log TTR drawing upon 61 works by Chaucer and two parts of the New Testament and stated that the index remained ‚Äúsensibly constant for samples of different size from as a style characteristic‚Äù (p.26, according to Hess et al., 1986<sup>[7](https://lcr-ads-lab.github.io/TAALED/references/1.%20Related%20Studies.html#hess-c-w-sefton-k-m--landry-r-g-1986)</sup>). 

* TTR values are intrinsically skewed by the length of a text, wherein longer texts tend to have lower TTR scores because the proportion of repeated words increases as the text grows longer (e.g., Koizumi & In'nami, 2012<sup>[11](https://lcr-ads-lab.github.io/TAALED/references/1.%20Related%20Studies.html#koizumi-r--innami-y-2012)</sup>; Tweedie & Baayen, 1998<sup>[20](https://lcr-ads-lab.github.io/TAALED/references/1.%20Related%20Studies.html#tweedie-f-j--baayen-r-h-1998)</sup>).

* Hess, Sefton, and Landry (1986)<sup>[7](https://lcr-ads-lab.github.io/TAALED/references/1.%20Related%20Studies.html#hess-c-w-sefton-k-m--landry-r-g-1986)</sup> analyzed oral language samples from 83 preschool children using five LD measures that were popular at the time: simple TTR, corrected TTR (Carroll, 1964<sup>[1](https://lcr-ads-lab.github.io/TAALED/references/1.%20Related%20Studies.html#carroll-j-b-1964)</sup>), Root TTR, Log TTR, and Characteristic K (Yule, 1944<sup>[21](https://lcr-ads-lab.github.io/TAALED/references/1.%20Related%20Studies.html#yule-g-u-1944)</sup>). They concluded that all these LD measures were unsuitable for comparing texts of different lengths.

* Hess, Haug, and Landry (1989)<sup>[6](https://lcr-ads-lab.github.io/TAALED/references/1.%20Related%20Studies.html#hess-c-w-haug-h--landry-r-g-1989)</sup> used oral language samples from 52 elementary school children to analyze four versions of TTR: simple TTR, corrected TTR, Root TTR, and Log TTR. As was the case in the earlier study by Hess et al. (1986)<sup>[7](https://lcr-ads-lab.github.io/TAALED/references/1.%20Related%20Studies.html#hess-c-w-sefton-k-m--landry-r-g-1986)</sup>, results suggested that none of the TTR measures were stable across texts of different lengths.

* In Malvern & Richards (2002)<sup>[15](https://lcr-ads-lab.github.io/TAALED/references/1.%20Related%20Studies.html#malvern-d--richards-b-2002)</sup>, MSTTR computes TTR values for equal-sized segments (sometimes 30 words, but more typically 100 words) out of the original text and averages the values for each non-overlapping segments. The remaining words are discarded. However, a number of weaknesses have been identified in this approach.

##### Previous studies with L1 corpus
* Tweedie and Baayen (1998)<sup>[20](https://lcr-ads-lab.github.io/TAALED/references/1.%20Related%20Studies.html#tweedie-f-j--baayen-r-h-1998)</sup>, see also Baayen & Tweedie, 1998) chose the twelve LD indices, including a few classic indices (e,g., root TTR, Maas) to test the text length effects. They evaluated their constancy across a range of text lengths using randomization techniques ‚Äì shuffling word orders randomly before measuring the values). The text lengths were decided by the English literature corpus, based on the fact that some of the literature consisted of relatively short words and some of them were not. They concluded that only a few measures were independent of the text length, but most were not.

* McCarthy and Jarvis (2007)<sup>[18](https://lcr-ads-lab.github.io/TAALED/references/1.%20Related%20Studies.html#mccarthy-p-m--jarvis-s-2007)</sup> used a parallel sampling technique to investigate the relationship between text length and LD indices in an L1 corpus of speaking and writing. They found that most indices (including TTR and root TTR) were strongly correlated with the text length.

##### A previous study with L2 spoken corpus
* Koizuimi (2012)<sup>[10](https://lcr-ads-lab.github.io/TAALED/references/1.%20Related%20Studies.html#koizumi-r-2012)</sup> evaluated TTR and Root TTR and the result indicated that both indices were not stable to the text length effects.

##### A previous study with L2 written corpus
* Zenker and Kyle (2021)<sup>[22](https://lcr-ads-lab.github.io/TAALED/references/1.%20Related%20Studies.html#zenker-f--kyle-k-2021)</sup> found out that well-known classic indices (i.e., simple TTR, root TTR, log TTR, MSTTR) were not stable across texts from 50 to 200 words in length.
