
# Save into a file

LD write function allows you to save your analysis into a txt file.

## 1. Import necessary packages
```python
from taaled import ld
from pylats import lats
from datetime import datetime #for creating an output filename
from datetime import date #for creating an output filename
import glob
```


## 2. Get a list of corpus files

```python
corp_path = "/Users/hakyungsung/Documents/TAALED/Corpus" #path to the folder where copora located in
sample = glob.glob(corp_path + "sample*.txt") #get list of filenames from the folder
len(sample) #check the number of the files in your folder
```


## 3. Define a file-naming function

```python
def outname_creator(fldname,isprll,other = None):
	day = date.today().strftime("%Y%m%d") #get date
	time = datetime.now().strftime("%H%M%S")
	ldv = "taaledv" + ld.version
	latsv = "pylatsv" + lats.version
	if isprll == True:
		pa = "pa"
	else:
		pa = "nopa"

	if other == None:
		outn = "_".join([day,time,fldname,pa]) + ".txt"
	else:
		outn = "_".join([day,time,fldname,pa,other]) + ".txt"

	return(outn)
	
	
outname = outname_creator("sample",False)	
```

## 4. Make an output file

```python
ld.ldwrite(sample,outname)  ("20220301_065208_stage234_nopa.txt")
#calculate ld for entire corpus: filename should be "date_time_sample_nopa(no parallel analysis).txt"


ld.ldwrite(sample,outname_creator("sample",True),mx = 200, prll = True) 
#run a parallel analysis for entire corpus-filename should be "date_time_sample_pa(parallel analysis).txt"
#you can change the mx number
```
### ►LEARN MORE: Parallel Analysis 
- Hess et al.(1986) used the parallel sampling method to divide each language sample into texts of different lengths. First, each sample was clipped to the first 200 tokens. Then the resulting texts were subdivided into four texts of 50 tokens, two texts of 100 tokens, one text of 150 tokens, and one text of 200 tokens. LD scores were then calculated for each text, and values from texts of the same length were averaged. Subsequent analysis using repeated measures ANOVAs showed that all the LD measures were significantly affected by text length (e.g., η2 = .82 for simple TTR). Hess et al. concluded that these LD measures were not suitable for making comparisons between texts of different lengths
- One of the few studies to investigate the minimum text lengths needed to produce stable LD values was carried out by Koizumi (2012), who evaluated simple TTR, Root TTR, vocd-D, and MTLD using spoken English samples from 20 Japanese adolescents. Each text was clipped to the first 200 words and then further subdivided into 25 segments ranging in length from 50 to 200 tokens by parallel sampling. LD values were calculated for each section and then averaged across sections of the same length. Results from repeated measures ANOVAs performed on the LD scores for five different text length ranges (50–100, 100–150, 150–200, 100–200, and 50–200) indicated that MTLD values stabilized at roughly 100 tokens. None of the other indices produced stable values within the text length ranges included in the study.
- First, each essay was clipped to the first 200 tokens. Then the parallel sampling method (Hess et al., 1986) was used to subdivide the essays into texts ranging from 50 to 200 tokens in length and increasing at increments of five tokens (four texts of 50 tokens, three texts of 55 tokens, etc.). Fifty tokens was chosen as the shortest text length because our procedure for calculating moving averages required a window of 50 tokens (Zenker & Kyle, 2021).


## Examples
1. a sample image of a non-parallel analysis 
<img width="1500" alt="image" src="https://user-images.githubusercontent.com/84297888/156243930-ec87bf0c-6426-4272-8dcc-838947cf15ee.png">



2. a sample image of a parallel analysis 
<img width="1500" alt="image" src="https://user-images.githubusercontent.com/84297888/156243988-ca865765-c60a-4b0c-a2af-761841fe260e.png">
